# Hallucinations
Hallucinations are words or phrases that are generated by the model that are often nonsensical or grammatically incorrect.

## Why this happens?
- The model is not trained on enough data
- The model is trained on noisy or dirty data
- The model is not given enough context
- The model is not given enough constraints

## Examples
### ShareStrike Date retreival fails
It was taking the ann_date. we had to give more context
